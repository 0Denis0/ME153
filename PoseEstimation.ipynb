{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7877770-a61e-4a22-97eb-6a4efd3f8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482096a9-e454-49f0-a066-a73909f388a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-1hfhc_rd\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 107\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m    105\u001b[0m     ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 107\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpose_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mARUCO_DICT\u001b[49m\u001b[43m[\u001b[49m\u001b[43maruco_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintrinsic_camera\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistortion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimated Pose\u001b[39m\u001b[38;5;124m'\u001b[39m, output)\n\u001b[0;32m    111\u001b[0m     key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 60\u001b[0m, in \u001b[0;36mpose_estimation\u001b[1;34m(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpose_estimation\u001b[39m(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n\u001b[1;32m---> 60\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     cv2\u001b[38;5;241m.\u001b[39maruco_dict \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mDictionary_get(aruco_dict_type)\n\u001b[0;32m     62\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mDetectorParameters_create()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-1hfhc_rd\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "ARUCO_DICT = {\n",
    "\t\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "\t\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "\t\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "\t\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "\t\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "\t\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "\t\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "\t\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "\t\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "\t\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "\t\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "\t\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "\t\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "\t\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "\t\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "\t\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "\t\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
    "\t\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
    "\t\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
    "\t\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
    "\t\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
    "}\n",
    "\n",
    "def aruco_display(corners, ids, rejected, image):\n",
    "    \n",
    "\tif len(corners) > 0:\n",
    "\t\t\n",
    "\t\tids = ids.flatten()\n",
    "\t\t\n",
    "\t\tfor (markerCorner, markerID) in zip(corners, ids):\n",
    "\t\t\t\n",
    "\t\t\tcorners = markerCorner.reshape((4, 2))\n",
    "\t\t\t(topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "\t\t\t\n",
    "\t\t\ttopRight = (int(topRight[0]), int(topRight[1]))\n",
    "\t\t\tbottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "\t\t\tbottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "\t\t\ttopLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "\n",
    "\t\t\tcv2.line(image, topLeft, topRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, topRight, bottomRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)\n",
    "\t\t\t\n",
    "\t\t\tcX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
    "\t\t\tcY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
    "\t\t\tcv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)\n",
    "\t\t\t\n",
    "\t\t\tcv2.putText(image, str(markerID),(topLeft[0], topLeft[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t0.5, (0, 255, 0), 2)\n",
    "\t\t\tprint(\"[Inference] ArUco marker ID: {}\".format(markerID))\n",
    "\t\t\t\n",
    "\treturn image\n",
    "\n",
    "\n",
    "\n",
    "def pose_estimation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.aruco_dict = cv2.aruco.Dictionary_get(aruco_dict_type)\n",
    "    parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "\n",
    "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, cv2.aruco_dict,parameters=parameters,\n",
    "        cameraMatrix=matrix_coefficients,\n",
    "        distCoeff=distortion_coefficients)\n",
    "\n",
    "        \n",
    "    if len(corners) > 0:\n",
    "        for i in range(0, len(ids)):\n",
    "           \n",
    "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], 0.02, matrix_coefficients,\n",
    "                                                                       distortion_coefficients)\n",
    "            \n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners) \n",
    "\n",
    "            cv2.aruco.drawAxis(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.01)  \n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "aruco_type = \"DICT_ARUCO_ORIGINAL\"\n",
    "\n",
    "arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[aruco_type])\n",
    "\n",
    "arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "\n",
    "intrinsic_camera = np.array(((933.15867, 0, 657.59),(0,933.1586, 400.36993),(0,0,1)))\n",
    "distortion = np.array((-0.43948,0.18514,0,0))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    output = pose_estimation(img, ARUCO_DICT[aruco_type], intrinsic_camera, distortion)\n",
    "\n",
    "    cv2.imshow('Estimated Pose', output)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c05e1-006c-491f-8d8d-1d0181036c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
