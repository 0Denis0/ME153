{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7877770-a61e-4a22-97eb-6a4efd3f8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b0e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this function by providing the marker corners, the pixel coordinates of the point of interest\n",
    "#(x is increasing to the right and y is increasing downward)\n",
    "# the length of the ArUco marker in m, the camera matrix, and the distortion coefficients. It will return the \n",
    "# distance from the ArUco marker to the point of interest in m.\n",
    "\n",
    "def distance_to_aruco(marker_corners, point_of_interest, marker_length, camera_matrix, dist_coeffs, marker_id):\n",
    "    # Obtain ArUco pose estimation\n",
    "    rvecs, tvecs, ids = cv2.aruco.estimatePoseSingleMarkers(marker_corners, marker_length, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Check if any markers are detected\n",
    "    if ids is None:\n",
    "        return None\n",
    "    \n",
    "    # Find the index of the marker with the specified ID\n",
    "    marker_index = np.where(ids == marker_id)[0]\n",
    "    \n",
    "    # Check if the specified marker ID is detected\n",
    "    if len(marker_index) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Extract the pose of the marker with the specified ID\n",
    "    marker_index = marker_index[0]  # Take the first marker with the specified ID\n",
    "    rvec_marker, tvec_marker = rvecs[marker_index], tvecs[marker_index]\n",
    "    \n",
    "    # Convert pixel coordinates of the point of interest to camera coordinates\n",
    "    homogeneous_pixel_coords = np.array([[point_of_interest[0]], [point_of_interest[1]], [1]])\n",
    "    homogeneous_camera_coords = np.dot(np.linalg.inv(camera_matrix), homogeneous_pixel_coords)\n",
    "    camera_coords = homogeneous_camera_coords / homogeneous_camera_coords[2]\n",
    "    \n",
    "    # Transform camera coordinates to marker coordinates for the marker with the specified ID\n",
    "    rotation_matrix_marker, _ = cv2.Rodrigues(rvec_marker)\n",
    "    marker_coords = np.dot(rotation_matrix_marker.T, (camera_coords - tvec_marker.T))\n",
    "    \n",
    "    # Return the vector instead of the absolute distance\n",
    "    return marker_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7023ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take an image and overlay evenly spaced circles within a specified box area.\n",
    "# Also it appends \n",
    "#Note: \n",
    "    # origin(0,0) of picture is at top-left corner\n",
    "    # x-axis increases to the right\n",
    "    # y-axis increases downward\n",
    "    \n",
    "def overlay_circles_on_image(image, num_points, circle_radius, circle_color, top_left, top_right, bottom_left, bottom_right):\n",
    "    # Convert numpy array to PIL Image\n",
    "    image_pil = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    \n",
    "    # Initialize an empty list to store the coordinates of the points\n",
    "    point_coordinates = []\n",
    "    \n",
    "    height = bottom_left[1] - top_left[1]\n",
    "    width = top_right[0] - top_left[0]\n",
    "    \n",
    "    y_points = np.linspace(top_left[1], bottom_left[1], num_points).astype(int)\n",
    "    x_points_left_to_right = np.linspace(top_left[0], top_right[0], num_points).astype(int)\n",
    "    x_points_right_to_left = np.linspace(top_right[0], top_left[0], num_points).astype(int)\n",
    "    \n",
    "    for y in y_points:\n",
    "        # Iterate from left to right\n",
    "        for x in x_points_left_to_right:\n",
    "            left_up_point = (x - circle_radius, y - circle_radius)\n",
    "            right_down_point = (x + circle_radius, y + circle_radius)\n",
    "            \n",
    "            # Append the coordinates of the current point to the list\n",
    "            point_coordinates.append((x, y))\n",
    "            \n",
    "            draw.ellipse([left_up_point, right_down_point], fill=circle_color)\n",
    "        \n",
    "        # Switch to iterating from right to left for the next row\n",
    "        x_points_left_to_right, x_points_right_to_left = x_points_right_to_left, x_points_left_to_right[::-1]\n",
    "    \n",
    "    # Convert the modified PIL Image back to a numpy array\n",
    "    modified_image = np.array(image_pil)\n",
    "    \n",
    "    # Return both the modified image and the list of point coordinates\n",
    "    return modified_image, point_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae10003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the relative rotation angles between two markers represented by their rotation \n",
    "# vectors rvec1 and rvec2. ( vec1 and rvec2 come from pose_estimation function.\n",
    "\n",
    "def angle_between_markers(rvec1, rvec2):\n",
    "    # Calculate relative rotation vectors\n",
    "    relative_rvec1 = rvec1 - np.array([0, 0, 0])  # Assume origin is at (0, 0, 0)\n",
    "    relative_rvec2 = rvec2 - np.array([0, 0, 0])  # Assume origin is at (0, 0, 0)\n",
    "\n",
    "    # Convert relative rotation vectors to rotation matrices\n",
    "    rotation_matrix1, _ = cv2.Rodrigues(relative_rvec1)\n",
    "    rotation_matrix2, _ = cv2.Rodrigues(relative_rvec2)\n",
    "\n",
    "    # Compute the rotation difference between the two markers\n",
    "    relative_rotation_matrix = np.dot(rotation_matrix2, np.linalg.inv(rotation_matrix1))\n",
    "        \n",
    "    # Convert rotation matrix to Euler angles\n",
    "    relative_euler_angles, _ = cv2.Rodrigues(relative_rotation_matrix)\n",
    "     \n",
    "    # Convert to Angles in x, y, and z\n",
    "    theta_x = np.arctan2(relative_rotation_matrix[2, 1], relative_rotation_matrix[2, 2])\n",
    "    theta_y = np.arctan2(-relative_rotation_matrix[2, 0], np.sqrt(relative_rotation_matrix[2, 1]**2 + relative_rotation_matrix[2, 2]**2))\n",
    "    theta_z = np.arctan2(relative_rotation_matrix[1, 0], relative_rotation_matrix[0, 0])\n",
    "    \n",
    "    # Convert to degrees\n",
    "    theta_x_deg = np.degrees(theta_x)\n",
    "    theta_y_deg = np.degrees(theta_y)\n",
    "    theta_z_deg = np.degrees(theta_z)\n",
    "    \n",
    "    # Make it a single matrix\n",
    "    Theta = np.array([theta_x_deg, theta_y_deg, theta_z_deg])\n",
    "        \n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead3edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the absolute distance between two aruco markers\n",
    "def distance_between_markers(tvec1, tvec2):\n",
    "    distance = np.linalg.norm(tvec1 - tvec2)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf92085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, rvec, tvec, camera_matrix, dist_coeffs, length):\n",
    "    axis_points = np.float32([[0,0,0], [length,0,0], [0,length,0], [0,0,length]]).reshape(-1,3)\n",
    "\n",
    "    # Project axis points to the image plane\n",
    "    img_points, _ = cv2.projectPoints(axis_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Convert image points to integers\n",
    "    img_points = np.round(img_points).astype(int)\n",
    "\n",
    "    # Draw lines\n",
    "    img = cv2.line(img, tuple(img_points[0].ravel()), tuple(img_points[1].ravel()), (0,0,255), 2)  # x-axis (red)\n",
    "    img = cv2.line(img, tuple(img_points[0].ravel()), tuple(img_points[2].ravel()), (0,255,0), 2)  # y-axis (green)\n",
    "    img = cv2.line(img, tuple(img_points[0].ravel()), tuple(img_points[3].ravel()), (255,0,0), 2)  # z-axis (blue)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0868255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aruco_display(corners, ids, rejected, image):  \n",
    "\tif len(corners) > 0:\n",
    "\t\t\n",
    "\t\tids = ids.flatten()\n",
    "\t\t\n",
    "\t\tfor (markerCorner, markerID) in zip(corners, ids):\n",
    "\t\t\t\n",
    "\t\t\tcorners = markerCorner.reshape((4, 2))\n",
    "\t\t\t(topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "\t\t\t\n",
    "\t\t\ttopRight = (int(topRight[0]), int(topRight[1]))\n",
    "\t\t\tbottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "\t\t\tbottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "\t\t\ttopLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "\n",
    "\t\t\tcv2.line(image, topLeft, topRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, topRight, bottomRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)\n",
    "\t\t\t\n",
    "\t\t\tcX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
    "\t\t\tcY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
    "\t\t\tcv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)\n",
    "\t\t\t\n",
    "\t\t\tcv2.putText(image, str(markerID),(topLeft[0], topLeft[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t0.5, (0, 255, 0), 2)\n",
    "\t\t\tprint(\"[Inference] ArUco marker ID: {}\".format(markerID))\n",
    "\t\t\t\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be52f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_estimation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(aruco_dict_type)  # Define aruco_dict here\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Call aruco_display to draw markers and their IDs\n",
    "    frame = aruco_display(corners, ids, rejected_img_points, frame)\n",
    "\n",
    "    if len(corners) > 1:\n",
    "        print(\"There are two or more markers\")\n",
    "        # Estimate pose for the first marker\n",
    "        rvec1, tvec1, _ = cv2.aruco.estimatePoseSingleMarkers(corners[0], 0.175, matrix_coefficients, distortion_coefficients)\n",
    "\n",
    "        # Estimate pose for the second marker\n",
    "        rvec2, tvec2, _ = cv2.aruco.estimatePoseSingleMarkers(corners[1], 0.175, matrix_coefficients, distortion_coefficients)\n",
    "        \n",
    "        # Calculating Relative Position Vectors\n",
    "        distance_vector = tvec1-tvec2;\n",
    "        distance = distance_between_markers(tvec1.squeeze(), tvec2.squeeze())\n",
    "        print(\"Distance between markers:\", distance)\n",
    "        print(\"Distance vector between markers:\", distance_vector)\n",
    "        \n",
    "        # Calculating Relative Rotations\n",
    "        Theta = angle_between_markers(rvec1.squeeze(), rvec2.squeeze()) \n",
    "        rot_aboutZ= Theta[2]\n",
    "        #print(f\"Relative Rotation Angle around X-axis (degrees): {Theta[0]}\")\n",
    "        #print(f\"Relative Rotation Angle around Y-axis (degrees): {Theta[1]}\")\n",
    "        print(f\"Relative Rotation Angle around Z-axis (degrees): {Theta[2]}\")\n",
    "        \n",
    "        dist1stpt = distance_to_aruco(corners, (500,100), 0.175, intrinsic_camera, distortion,153)\n",
    "        print(\"Distance between Aruco marker and point:\", dist1stpt)\n",
    "        \n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners)\n",
    "        draw_axis(frame, rvec1, tvec1, matrix_coefficients, distortion_coefficients, 0.1)\n",
    "        draw_axis(frame, rvec2, tvec2, matrix_coefficients, distortion_coefficients, 0.1)\n",
    "\n",
    "    return frame, distance_vector, rot_aboutZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa046ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ']' (4018089172.py, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 53\u001b[0;36m\u001b[0m\n\u001b[0;31m    break]\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ']'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "ARUCO_DICT = {\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,}\n",
    "\n",
    "aruco_type = \"DICT_ARUCO_ORIGINAL\"\n",
    "\n",
    "arucoDict = cv2.aruco.getPredefinedDictionary(ARUCO_DICT[aruco_type])\n",
    "\n",
    "arucoParams = cv2.aruco.DetectorParameters()\n",
    "\n",
    "\n",
    "intrinsic_camera = np.array(((933.15867, 0, 657.59),(0,933.1586, 400.36993),(0,0,1)))\n",
    "distortion = np.array((-0.43948,0.18514,0,0))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# While loop for computer vision, currently calculates distance between markers only\n",
    "while cap.isOpened():\n",
    "     \n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # Calculates Position of Arucos and outputs the image with the axises and ids overlaid\n",
    "    output,_ = pose_estimation(img, ARUCO_DICT[aruco_type], intrinsic_camera, distortion)\n",
    "    \n",
    "    # Add the Circle Overlay\n",
    "    processed_image, point_coordinates = overlay_circles_on_image(\n",
    "        output,\n",
    "        num_points=10,\n",
    "        circle_radius=3,\n",
    "        circle_color=(255, 215, 0, 255),\n",
    "        top_left=(500, 100),\n",
    "        top_right=(1000, 100),\n",
    "        bottom_left=(500, 500),\n",
    "        bottom_right=(1000, 500)\n",
    "    )\n",
    "\n",
    "#     # Calculate distance between the Aruco marker and the first point\n",
    "#     dist1stpt = distance_to_aruco(corners, point_coordinates[0], 0.175, intrinsic_camera, distortion,153)\n",
    "#     print(\"Distance between Aruco marker and point:\", dist1stpt)\n",
    "    cv2.imshow('Estimated Pose',  processed_image)\n",
    "\n",
    "    # Get the corners and ids of detected markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(img, arucoDict, parameters=arucoParams)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break]\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17bd9cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(500, 100),\n",
       " (555, 100),\n",
       " (611, 100),\n",
       " (666, 100),\n",
       " (722, 100),\n",
       " (777, 100),\n",
       " (833, 100),\n",
       " (888, 100),\n",
       " (944, 100),\n",
       " (1000, 100),\n",
       " (1000, 144),\n",
       " (944, 144),\n",
       " (888, 144),\n",
       " (833, 144),\n",
       " (777, 144),\n",
       " (722, 144),\n",
       " (666, 144),\n",
       " (611, 144),\n",
       " (555, 144),\n",
       " (500, 144),\n",
       " (1000, 188),\n",
       " (944, 188),\n",
       " (888, 188),\n",
       " (833, 188),\n",
       " (777, 188),\n",
       " (722, 188),\n",
       " (666, 188),\n",
       " (611, 188),\n",
       " (555, 188),\n",
       " (500, 188),\n",
       " (500, 233),\n",
       " (555, 233),\n",
       " (611, 233),\n",
       " (666, 233),\n",
       " (722, 233),\n",
       " (777, 233),\n",
       " (833, 233),\n",
       " (888, 233),\n",
       " (944, 233),\n",
       " (1000, 233),\n",
       " (500, 277),\n",
       " (555, 277),\n",
       " (611, 277),\n",
       " (666, 277),\n",
       " (722, 277),\n",
       " (777, 277),\n",
       " (833, 277),\n",
       " (888, 277),\n",
       " (944, 277),\n",
       " (1000, 277),\n",
       " (1000, 322),\n",
       " (944, 322),\n",
       " (888, 322),\n",
       " (833, 322),\n",
       " (777, 322),\n",
       " (722, 322),\n",
       " (666, 322),\n",
       " (611, 322),\n",
       " (555, 322),\n",
       " (500, 322),\n",
       " (1000, 366),\n",
       " (944, 366),\n",
       " (888, 366),\n",
       " (833, 366),\n",
       " (777, 366),\n",
       " (722, 366),\n",
       " (666, 366),\n",
       " (611, 366),\n",
       " (555, 366),\n",
       " (500, 366),\n",
       " (500, 411),\n",
       " (555, 411),\n",
       " (611, 411),\n",
       " (666, 411),\n",
       " (722, 411),\n",
       " (777, 411),\n",
       " (833, 411),\n",
       " (888, 411),\n",
       " (944, 411),\n",
       " (1000, 411),\n",
       " (500, 455),\n",
       " (555, 455),\n",
       " (611, 455),\n",
       " (666, 455),\n",
       " (722, 455),\n",
       " (777, 455),\n",
       " (833, 455),\n",
       " (888, 455),\n",
       " (944, 455),\n",
       " (1000, 455),\n",
       " (1000, 500),\n",
       " (944, 500),\n",
       " (888, 500),\n",
       " (833, 500),\n",
       " (777, 500),\n",
       " (722, 500),\n",
       " (666, 500),\n",
       " (611, 500),\n",
       " (555, 500),\n",
       " (500, 500)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71749528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
