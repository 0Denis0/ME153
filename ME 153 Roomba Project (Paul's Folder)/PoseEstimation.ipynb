{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7877770-a61e-4a22-97eb-6a4efd3f8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b0e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this function by providing the marker corners, the pixel coordinates of the point of interest\n",
    "#(x is increasing to the right and y is increasing downward)\n",
    "# the length of the ArUco marker in m, the camera matrix, and the distortion coefficients. It will return the \n",
    "# distance from the ArUco marker to the point of interest in m.\n",
    "\n",
    "def distance_to_aruco(marker_corners, point_of_interest, marker_length, camera_matrix, dist_coeffs):\n",
    "    # Obtain ArUco pose estimation\n",
    "    rvec, tvec, _ = cv2.aruco.estimatePoseSingleMarkers(marker_corners, marker_length, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Convert pixel coordinates of the point of interest to camera coordinates\n",
    "    homogeneous_pixel_coords = np.array([[point_of_interest[0]], [point_of_interest[1]], [1]])\n",
    "    homogeneous_camera_coords = np.dot(np.linalg.inv(camera_matrix), homogeneous_pixel_coords)\n",
    "    camera_coords = homogeneous_camera_coords / homogeneous_camera_coords[2]\n",
    "    \n",
    "    # Transform camera coordinates to marker coordinates\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "    marker_coords = np.dot(rotation_matrix.T, (camera_coords - tvec.T))\n",
    "    \n",
    "    # Compute the distance from marker origin to the transformed point\n",
    "    distance = np.linalg.norm(marker_coords)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e7023ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take an image and overlay evenly spaced circles within a specified box area.\n",
    "\n",
    "#Note: \n",
    "    # origin(0,0) of picture is at top-left corner\n",
    "    # x-axis increases to the right\n",
    "    # y-axis increases downward\n",
    "    \n",
    "def overlay_circles_on_image(image, num_points, circle_radius, circle_color, top_left, top_right, bottom_left, bottom_right):\n",
    "    # Convert numpy array to PIL Image\n",
    "    image_pil = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    height = bottom_left[1] - top_left[1]\n",
    "    width = top_right[0] - top_left[0]\n",
    "    y_points = np.linspace(top_left[1], bottom_left[1], num_points).astype(int)\n",
    "    x_points = np.linspace(top_left[0], top_right[0], num_points).astype(int)\n",
    "    for y in y_points:\n",
    "        for x in x_points:\n",
    "            left_up_point = (x - circle_radius, y - circle_radius)\n",
    "            right_down_point = (x + circle_radius, y + circle_radius)\n",
    "            draw.ellipse([left_up_point, right_down_point], fill=circle_color)\n",
    "    return np.array(image_pil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62f1e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the relative rotation angles between two markers represented by their rotation \n",
    "# vectors rvec1 and rvec2. ( vec1 and rvec2 come from pose_estimation function.\n",
    "\n",
    "def angle_between_markers(rvec1, rvec2):\n",
    "    # Calculate relative rotation vectors\n",
    "    relative_rvec1 = rvec1 - np.array([0, 0, 0])  # Assume origin is at (0, 0, 0)\n",
    "    relative_rvec2 = rvec2 - np.array([0, 0, 0])  # Assume origin is at (0, 0, 0)\n",
    "\n",
    "    # Convert relative rotation vectors to rotation matrices\n",
    "    rotation_matrix1, _ = cv2.Rodrigues(relative_rvec1)\n",
    "    rotation_matrix2, _ = cv2.Rodrigues(relative_rvec2)\n",
    "\n",
    "    # Compute the rotation difference between the two markers\n",
    "    relative_rotation_matrix = np.dot(rotation_matrix2, np.linalg.inv(rotation_matrix1))\n",
    "        \n",
    "    # Convert rotation matrix to Euler angles\n",
    "    relative_euler_angles, _ = cv2.Rodrigues(relative_rotation_matrix)\n",
    "     \n",
    "    # Convert to Angles in x, y, and z\n",
    "    theta_x = np.arctan2(relative_rotation_matrix[2, 1], relative_rotation_matrix[2, 2])\n",
    "    theta_y = np.arctan2(-relative_rotation_matrix[2, 0], np.sqrt(relative_rotation_matrix[2, 1]**2 + relative_rotation_matrix[2, 2]**2))\n",
    "    theta_z = np.arctan2(relative_rotation_matrix[1, 0], relative_rotation_matrix[0, 0])\n",
    "    \n",
    "    # Convert to degrees\n",
    "    theta_x_deg = np.degrees(theta_x)\n",
    "    theta_y_deg = np.degrees(theta_y)\n",
    "    theta_z_deg = np.degrees(theta_z)\n",
    "    \n",
    "    # Make it a single matrix\n",
    "    Theta = np.array([theta_x_deg, theta_y_deg, theta_z_deg])\n",
    "        \n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the absolute distance between two aruco markers\n",
    "def distance_between_markers(tvec1, tvec2):\n",
    "    distance = np.linalg.norm(tvec1 - tvec2)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01916506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, rvec, tvec, camera_matrix, dist_coeffs, length):\n",
    "    axis_points = np.float32([[0,0,0], [length,0,0], [0,length,0], [0,0,length]]).reshape(-1,3)\n",
    "\n",
    "    # Project axis points to the image plane\n",
    "    img_points, _ = cv2.projectPoints(axis_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Convert image points to integers\n",
    "    img_points = np.round(img_points).astype(int)\n",
    "\n",
    "    # Draw lines\n",
    "    img = cv2.line(img, tuple(img_points[0].ravel()), tuple(img_points[1].ravel()), (0,0,255), 2)  # x-axis (red)\n",
    "    img = cv2.line(img, tuple(img_points[0].ravel()), tuple(img_points[2].ravel()), (0,255,0), 2)  # y-axis (green)\n",
    "    img = cv2.line(img, tuple(img_points[0].ravel()), tuple(img_points[3].ravel()), (255,0,0), 2)  # z-axis (blue)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92131ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aruco_display(corners, ids, rejected, image):  \n",
    "\tif len(corners) > 0:\n",
    "\t\t\n",
    "\t\tids = ids.flatten()\n",
    "\t\t\n",
    "\t\tfor (markerCorner, markerID) in zip(corners, ids):\n",
    "\t\t\t\n",
    "\t\t\tcorners = markerCorner.reshape((4, 2))\n",
    "\t\t\t(topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "\t\t\t\n",
    "\t\t\ttopRight = (int(topRight[0]), int(topRight[1]))\n",
    "\t\t\tbottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "\t\t\tbottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "\t\t\ttopLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "\n",
    "\t\t\tcv2.line(image, topLeft, topRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, topRight, bottomRight, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
    "\t\t\tcv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)\n",
    "\t\t\t\n",
    "\t\t\tcX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
    "\t\t\tcY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
    "\t\t\tcv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)\n",
    "\t\t\t\n",
    "\t\t\tcv2.putText(image, str(markerID),(topLeft[0], topLeft[1] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t\t\t0.5, (0, 255, 0), 2)\n",
    "\t\t\tprint(\"[Inference] ArUco marker ID: {}\".format(markerID))\n",
    "\t\t\t\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_estimation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(aruco_dict_type)  # Define aruco_dict here\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # Call aruco_display to draw markers and their IDs\n",
    "    frame = aruco_display(corners, ids, rejected_img_points, frame)\n",
    "\n",
    "    if len(corners) > 1:\n",
    "        print(\"There are two or more markers\")\n",
    "        # Estimate pose for the first marker\n",
    "        rvec1, tvec1, _ = cv2.aruco.estimatePoseSingleMarkers(corners[0], 0.175, matrix_coefficients, distortion_coefficients)\n",
    "\n",
    "        # Estimate pose for the second marker\n",
    "        rvec2, tvec2, _ = cv2.aruco.estimatePoseSingleMarkers(corners[1], 0.175, matrix_coefficients, distortion_coefficients)\n",
    "        \n",
    "        # Calculating Relative Position Vectors\n",
    "        distance_vector = tvec1-tvec2;\n",
    "        distance = distance_between_markers(tvec1.squeeze(), tvec2.squeeze())\n",
    "        print(\"Distance between markers:\", distance)\n",
    "        print(\"Distance vector between markers:\", distance_vector)\n",
    "        \n",
    "        # Calculating Relative Rotations\n",
    "        Theta = angle_between_markers(rvec1.squeeze(), rvec2.squeeze())  \n",
    "        #print(f\"Relative Rotation Angle around X-axis (degrees): {Theta[0]}\")\n",
    "        #print(f\"Relative Rotation Angle around Y-axis (degrees): {Theta[1]}\")\n",
    "        print(f\"Relative Rotation Angle around Z-axis (degrees): {Theta[2]}\")\n",
    "        \n",
    "        # Calculating distance to top-left point\n",
    "        poin_of_interest = \n",
    "        distance_to_aruco = distance_to_aruco(corners, point_of_interest, 0.175, camera_matrix, dist_coeffs)\n",
    "        \n",
    "        \n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners)\n",
    "        draw_axis(frame, rvec1, tvec1, matrix_coefficients, distortion_coefficients, 0.1)\n",
    "        draw_axis(frame, rvec2, tvec2, matrix_coefficients, distortion_coefficients, 0.1)\n",
    "\n",
    "    return frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f4f2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n",
      "[Inference] ArUco marker ID: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "ARUCO_DICT = {\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,}\n",
    "\n",
    "aruco_type = \"DICT_ARUCO_ORIGINAL\"\n",
    "\n",
    "arucoDict = cv2.aruco.getPredefinedDictionary(ARUCO_DICT[aruco_type])\n",
    "\n",
    "arucoParams = cv2.aruco.DetectorParameters()\n",
    "\n",
    "\n",
    "intrinsic_camera = np.array(((933.15867, 0, 657.59),(0,933.1586, 400.36993),(0,0,1)))\n",
    "distortion = np.array((-0.43948,0.18514,0,0))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# While loop for computer vision, currently calculates distance between markers only\n",
    "while cap.isOpened():\n",
    "     \n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # Calculates Position of Arucos and outputs the image with the axises and ids overlaid\n",
    "    output = pose_estimation(img, ARUCO_DICT[aruco_type], intrinsic_camera, distortion)\n",
    "    \n",
    "    # Add the Circle Overlay\n",
    "    processed_image = overlay_circles_on_image(\n",
    "    output,\n",
    "    num_points=10,\n",
    "    circle_radius=3,\n",
    "    circle_color=(0, 0, 255, 255),\n",
    "    top_left=(500, 100),  \n",
    "    top_right=(1000, 100),   \n",
    "    bottom_left=(500, 500),  \n",
    "    bottom_right=(1000, 500) \n",
    "    )\n",
    "    cv2.imshow('Estimated Pose',  processed_image)\n",
    "   \n",
    "    # Get the corners and ids of detected markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(img, arucoDict, parameters=arucoParams)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43221b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
